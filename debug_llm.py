"""
Step-by-step LLM Debug Script
Tests each component of the LLM pipeline to identify failure points
"""

import asyncio
import json
from transformers import pipeline
import time

def test_llm_initialization():
    """Test 1: Check if LLM model loads properly"""
    print("ğŸ” Test 1: LLM Model Initialization")
    print("=" * 50)
    
    try:
        print("ğŸ¤– Loading GPT-2 model...")
        start_time = time.time()
        
        text_generator = pipeline("text-generation", model="openai-community/gpt2", device="cpu")
        
        load_time = time.time() - start_time
        print(f"âœ… Model loaded successfully in {load_time:.2f}s")
        
        # Test basic generation
        test_prompt = "Hello world"
        print(f"ğŸ§ª Testing basic generation with prompt: '{test_prompt}'")
        
        start_time = time.time()
        result = text_generator(test_prompt, max_new_tokens=10, num_return_sequences=1)
        gen_time = time.time() - start_time
        
        print(f"âœ… Basic generation successful in {gen_time:.2f}s")
        print(f"ğŸ“ Generated text: {result[0]['generated_text'][:100]}...")
        
        return text_generator
        
    except Exception as e:
        print(f"âŒ LLM initialization failed: {e}")
        return None

def test_simple_prompt(text_generator):
    """Test 2: Test simple prompt generation"""
    print("\nğŸ” Test 2: Simple Prompt Generation")
    print("=" * 50)
    
    try:
        prompt = "Generate a list of 3 topics:"
        print(f"ğŸ“ Testing prompt: '{prompt}'")
        
        start_time = time.time()
        result = text_generator(prompt, max_new_tokens=50, num_return_sequences=1)
        gen_time = time.time() - start_time
        
        print(f"âœ… Generation successful in {gen_time:.2f}s")
        print(f"ğŸ“ Full response: {result[0]['generated_text']}")
        
        return result[0]['generated_text']
        
    except Exception as e:
        print(f"âŒ Simple prompt failed: {e}")
        return None

def test_json_prompt(text_generator):
    """Test 3: Test JSON-specific prompt"""
    print("\nğŸ” Test 3: JSON Prompt Generation")
    print("=" * 50)
    
    try:
        prompt = """Task: Generate trending topics for a YouTube channel.

Channel content: Channel with 5 videos covering topics like Bitcoin, Ethereum, DeFi
Target region: global
Target language: en

Instructions:
1. Identify 5 trending topics this channel hasn't covered yet
2. Focus on high-search-volume topics in this niche
3. Return ONLY a JSON object with this exact structure

Required JSON format:
{"trending_topics": ["topic1", "topic2", "topic3", "topic4", "topic5"]}

Example valid response:
{"trending_topics": ["AI Trends", "Digital Transformation", "Remote Work", "Sustainability", "Health Tech"]}

Do not include any explanations, examples, or additional text. Only return the JSON object."""
        
        print(f"ğŸ“ Testing JSON prompt (length: {len(prompt)} characters)")
        
        start_time = time.time()
        result = text_generator(prompt, max_new_tokens=100, num_return_sequences=1)
        gen_time = time.time() - start_time
        
        print(f"âœ… JSON generation successful in {gen_time:.2f}s")
        print(f"ğŸ“ Full response: {result[0]['generated_text']}")
        
        return result[0]['generated_text']
        
    except Exception as e:
        print(f"âŒ JSON prompt failed: {e}")
        return None

def test_json_parsing(response):
    """Test 4: Test JSON parsing from response"""
    print("\nğŸ” Test 4: JSON Parsing")
    print("=" * 50)
    
    if not response:
        print("âŒ No response to parse")
        return None
    
    try:
        print(f"ğŸ“ Attempting to parse: {response}")
        
        # Remove the prompt from response
        clean_response = response.replace("Task: Generate trending topics for a YouTube channel.", "").strip()
        print(f"ğŸ§¹ Cleaned response: {clean_response}")
        
        # Try to find JSON object
        json_start = clean_response.find('{')
        json_end = clean_response.rfind('}') + 1
        
        if json_start != -1 and json_end > json_start:
            json_str = clean_response[json_start:json_end]
            print(f"ğŸ“‹ Extracted JSON: {json_str}")
            
            # Try to parse
            parsed = json.loads(json_str)
            print(f"âœ… JSON parsing successful: {parsed}")
            return parsed
        else:
            print("âŒ No JSON braces found in response")
            return None
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSON decode error: {e}")
        return None
    except Exception as e:
        print(f"âŒ JSON parsing failed: {e}")
        return None

def test_timeout_handling(text_generator):
    """Test 5: Test timeout handling"""
    print("\nğŸ” Test 5: Timeout Handling")
    print("=" * 50)
    
    try:
        # Test with different token limits
        token_limits = [50, 100, 200, 300]
        
        for tokens in token_limits:
            print(f"ğŸ§ª Testing with {tokens} tokens...")
            
            start_time = time.time()
            result = text_generator("Generate a simple response", max_new_tokens=tokens, num_return_sequences=1)
            gen_time = time.time() - start_time
            
            print(f"âœ… {tokens} tokens generated in {gen_time:.2f}s")
            
            if gen_time > 30:
                print(f"âš ï¸  Warning: {tokens} tokens took {gen_time:.2f}s (slow)")
        
        return True
        
    except Exception as e:
        print(f"âŒ Timeout test failed: {e}")
        return False

def main():
    """Run all debug tests"""
    print("ğŸ§ª LLM Step-by-Step Debug")
    print("=" * 60)
    
    # Test 1: Model initialization
    text_generator = test_llm_initialization()
    if not text_generator:
        print("âŒ Cannot proceed without LLM model")
        return
    
    # Test 2: Simple prompt
    simple_response = test_simple_prompt(text_generator)
    if not simple_response:
        print("âŒ Simple prompt failed")
        return
    
    # Test 3: JSON prompt
    json_response = test_json_prompt(text_generator)
    if not json_response:
        print("âŒ JSON prompt failed")
        return
    
    # Test 4: JSON parsing
    parsed_json = test_json_parsing(json_response)
    if not parsed_json:
        print("âŒ JSON parsing failed")
        return
    
    # Test 5: Timeout handling
    timeout_ok = test_timeout_handling(text_generator)
    if not timeout_ok:
        print("âŒ Timeout handling failed")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ‰ All debug tests completed!")
    print("\nğŸ“Š Summary:")
    print("  âœ… LLM model loads correctly")
    print("  âœ… Basic generation works")
    print("  âœ… JSON prompts work")
    print("  âœ… JSON parsing works")
    print("  âœ… Timeout handling works")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"âŒ Debug script failed: {e}")
        import traceback
        traceback.print_exc() 